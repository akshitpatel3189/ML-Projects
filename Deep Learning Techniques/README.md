#   Deep Learning Techniques

In this project, I am demonstrating various deep learning techniques, including fully connected networks, batch normalization, dropout, and convolutional networks using PyTorch.


# Tools and Libraries

I am using Jupyter Notebook for this project.
For running this project I have used the following Python libraries
-   pandas
-   PyTorch
-   Torchvision
-   matplotlib


# Description:

I have used the MNIST dataset which is provided in the dataset_link.txt file.

First I have implemented a fully-connected network. Then I apply and compare at least three popular update rules, such as Stochastic Gradient Descent (SGD), Momentum SGD, RMSprop, and Adam. Evaluate the performance differences introduced by selected optimization methods.

Then I modify the fully-connected network with batch normalization and compare the  
performance of the network with and without batch normalization.

After that I implement dropout explore its effects on fully-connected network and compare the performance of the network with and without dropout.

Then I implement a convolutional neural network (CNN) using PyTorch and MNIST dataset. It includes one convolutional layer, one pooling layer, and one fully-connected layer.

Finally, with PyTorch, I train a model on the MNIST dataset. and optimize the model's performance.
